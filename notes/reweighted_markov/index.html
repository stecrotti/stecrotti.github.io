<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Reweighted Markov processes | Stefano Crotti </title> <meta name="author" content="Stefano Crotti"> <meta name="description" content="PhD in Physics "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%8D%A4&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://stecrotti.github.io/notes/reweighted_markov/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> <script src="/assets/js/distillpub/overrides.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Reweighted Markov processes",
            "description": "",
            "published": "June 11, 2025",
            "authors": [
              
              {
                "author": "Stefano Crotti",
                "authorURL": "",
                "affiliations": [
                  {
                    "name": "Politecnico di Torino, Italy",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Stefano</span> Crotti </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/portfolio/">Portfolio </a> </li> <li class="nav-item active"> <a class="nav-link" href="/notes/">Notes <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/pybits/index.html">PyBits </a> </li> <li class="nav-item "> <a class="nav-link" href="/Links/">Links </a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/cv.pdf">CV </a> </li> </ul> </div> </div> </nav> </header> <div class="post distill"> <d-title> <h1>Reweighted Markov processes</h1> <p></p> </d-title> <d-byline></d-byline> <d-article> <p>When I first started working on reweighted stochastic processes, it was not clear to me why they should be computationally more challenging than their “free” version. Here is a tentative explanation of why and to which extent this is true. It was first conceived to be read by a friend who is a physicist but is not so used to manipulating probability distributions.</p> <h3 id="mini-review-of-conditional-probability">Mini review of conditional probability</h3> <p>Any distribution over discrete random variables \(p(x_{1},x_{2},\ldots,x_{n})\) can be written as</p> \[\begin{equation} p(x_{1},x_{2},\ldots,x_{n})=p(x_{1})p(x_{2}|x_{1})p(x_{3}|x_{1},x_{2})\cdots p(x_{n}|x_{1},x_{2},\ldots,x_{n-1}) \end{equation}\] <p>by repeated application of the definition of conditional probability \(p(A|B)=\frac{p(A,B)}{P(B)}.\)</p> <p>We did nothing really, and indeed the RHS of \((1)\) is just as complicated to treat as the LHS. However this can be the first step towards significant simplifications, as will be clear in the following.</p> <h3 id="a-word-about-notation">A word about notation</h3> <p>Probability is usually defined in terms of events: we call \(p(A)\) the probability that event \(A\) happens. When random variables come into play we shift point of view and work with \(p(X=x)\), the probability of the event “variable \(X\) takes value \(x\)”. It is common practice to use the same letter for the random variable and its value, upper and lowercase respectively, and to simply write \(p(x)\) for short.</p> <h2 id="markov-processes">Markov processes</h2> <p>A <a href="https://en.wikipedia.org/wiki/Markov_chain" rel="external nofollow noopener" target="_blank">Markov process</a>, also known as Markov chain, is a sequence \(X^{1},X^{2},\ldots,X^{T}\) of random variables with the property that the distribution of \(X^{t}\) depends only on the value of \(X^{t-1}\). Mathematically this means that \(p(x^{t}|x^{1},x^{2}\ldots,x^{t-1})=p(x^{t}|x^{t-1})\) for all \(t=2,\ldots T\). The starting point is some \(p(x^{1})\).</p> <p>Combining this property with the decomposition \((1)\) we get</p> \[\begin{align} p(x^{1})p(x^{2}|x^{1})p(x^{3}|x^{1},x^{2})\cdots p(x^{T}|x^{1},x^{2},\ldots,x^{T-1})= &amp; p(x^{1})p(x^{2}|x^{1})p(x^{3}|x^{2})\cdots p(x^{T}|x^{T-1}) \end{align}\] <p>Therefore the joint probability for a Markov process reads</p> \[\begin{align} p(x^{1},x^{2},\ldots,x^{T})= &amp; p(x^{1})\prod_{t=2}^{T}p(x^{t}|x^{t-1}) \end{align}\] <p>One tends to consider distribtions like this “tractable” because a bunch of operations of interest can be performed efficiently:</p> <ul> <li>Compute the normalization: this is trivial, the distribution is already normalized</li> </ul> \[\begin{equation} \sum_{x^{1},x^{2},\ldots,x^{T}}p(x^{1})\prod_{t=2}^{T}p(x^{t}|x^{t-1})=\sum_{x^{1}}p(x^{1})\prod_{t=2}^{T}\sum_{x^{t}}p(x^{t}|x^{t-1})=1 \end{equation}\] <ul> <li>Compute marginals: this is done iteratively starting from \(p(x^{1})\). Then</li> </ul> \[\begin{equation} p(x^{t})=\sum_{x^{t-1}}p(x^{t-1},x^{t})=\sum_{x^{t-1}}p(x^{t}|x^{t-1})p(x^{t-1}) \end{equation}\quad\forall t \in 2,\ldots,T\] <p>with a computational cost of \(\mathcal{O}(q^2T)\) where \(q\) is the number of values each \(X^{t}\) can take.</p> <ul> <li>Sample exactly: the distribution is already written in a form that is almost begging you to sample from it</li> </ul> \[\begin{equation} \begin{aligned}x^{1}\sim &amp; p(x^{1})\\ x^{2}\sim &amp; p(x^{2}|x^{1})\\ \vdots\\ x^{T}\sim &amp; p(x^{T}|x^{T-1}) \end{aligned} \end{equation}\] <p>with a cost \(\mathcal{O}(qT)\).</p> <h3 id="example-1d-random-walk">Example: 1D random walk</h3> <p>A one-dimensional random walk describes a particle hopping left or right on a one-dimensional lattice at discrete time steps. Variable \(X^{t}\) is the position of the particle at time \(t\): it changes by \(-1,+1\) when the particle hops left or right, respectively. In the simplest case where the probability of going left or right does not depend on time we have</p> \[\begin{equation} p(x^{t}|x^{t-1})=p_{left}\delta(x^{t},x^{t-1}-1)+p_{right}\delta(x^{t},x^{t-1}+1) \end{equation}\] <p>with \(p_{left}+p_{right}=1\). In general one could have different \((p_{left}^{t},p_{right}^{t})\) at each timestep.</p> <h2 id="reweighted-markov-processes">Reweighted Markov processes</h2> <p>We can now study distributions that are obtained from Markov processes by tilting the distribution with a reweighting factor. The most general object we consider is</p> \[\begin{equation} p(x^{1},x^{2},\ldots,x^{T})\propto W(x^{1},x^{2},\ldots,x^{T})\Phi(x^{1},x^{2},\ldots,x^{T}) \end{equation}\] <p>where \(W\) is a Markov process and \(\Phi\) an arbitrary non-negative-valued function. More explicitly,</p> \[\begin{equation} p(x^{1},x^{2},\ldots,x^{T})=\frac{w^{1}(x^{1}){ \prod_{t=2}^{T}w^{t}(x^{t}|x^{t-1})}\Phi(x^{1},x^{2},\ldots,x^{T})}{Z} \end{equation}\] <p>with \(\sum_{x^{t}}w^{t}(x^{t}|x^{t-1})=1\) and \(Z\) the normalization constant. </p> <p>This is <strong>not a Markov process</strong> anymore! Should you need to convince yourself, try computing \(p(x^{t}|x^{1},x^{2}\ldots,x^{t-1})\) as, by definition, \(\frac{p(x^{1},x^{2},\ldots,x^{t})}{\sum_{x^{t}}p(x^{1},x^{2},\ldots,x^{t})}\). In the case without reweighting \((1)\) you will get back the Markov property \(p(x^{t}|x^{1},x^{2}\ldots,x^{t-1})=p(x^{t}|x^{t-1})\). The same procedure fails for a reweighted process.</p> <p>It is not hard to show that <strong>none of the 3 operations that were easy for Markov processes are affordable anymore: normalizing, computing marginals and sampling from \((8)\) all have a cost that scales exponentially with \(T\)</strong>.</p> <h3 id="example-constrained-1d-random-walk">Example: constrained 1D random walk</h3> <p>A 1D random walk that has been constrained to land at a certain point \(x_{final}\) at the final time \(T\). We have</p> \[\begin{equation} \begin{cases} w^{t}(x^{t}|x^{t-1}) &amp; =p_{left}\delta(x^{t},L)+(1-p_{left})\delta(x^{t},R)\\ \Phi(x^{1},x^{2},\ldots,x^{T}) &amp; =\delta(x^{T},x_{final}) \end{cases} \end{equation}\] <p>Already for such a simple example it is hopefully clear how things became much more involved with respect to the case with no reweighting. For instance, how does one go about sampling from such a distribution? An idea is to draw trajectories from the free distribution \(w^{1}(x^{1}){ \prod_{t=2}^{T}w^{t}(x^{t}|x^{t-1})}\) and then discard those samples that do not fulfill the constraint. This is an honest, unbiased sampler. However, in cases where the probability of a trajectory satisfying the constraint is very small, the number of discarded samples before finding a good one can become huge, making the whole process a computational nightmare. Indeed, in more complex settings, one is often interested in realizations of the process which are extremely rare <d-cite key="crotti2023large"></d-cite>.</p> <h2 id="multivariate-distributions">Multivariate distributions</h2> <p>All of the above works just as well if, at each time step \(t\), \(X^{t}\) is a random vector, i.e. a set of random variables \(\boldsymbol{X}^{t}=(X_{1}^{t},X_{2}^{t},\ldots,X_{N}^{t})\). For example, \(\boldsymbol{X}^{t}\) could describe the state of a system of \(N\) interacting particles. The problem of computing marginals and sampling for a non-reweighted process is in general not easy anymore: the cost scales as \(\mathcal{O}(q^{N}T)\) which quickly becomes prohibitive as \(N\) grows (here we renamed \(q\) the number of values taken by a single \(X_{i}^{t}\), therefore \(\boldsymbol{X}^{t}\) can take \(q^{N}\)values).</p> <p>The multivariate <em>and</em> biased case is <strong>doubly hard</strong>: typical quantities of interest are the marginal distributions</p> \[\begin{equation} p(x_{i}^{t})=\sum_{\{x_{j}^{t}\}_{j\neq i}}p(\boldsymbol{x}^{t})=\sum_{\{x_{j}^{s}\}_{j\neq i,s\neq t}}p(x^{1},x^{2},\ldots,x^{T}) \end{equation}\] <p>which require a <strong>doubly exponential</strong> \(\mathcal{O}(q^{NT})\) number of operations to be computed.</p> <h3 id="example-epidemic-spreading-according-to-the-si-model">Example: Epidemic spreading according to the SI model</h3> <p>The SI (Susceptible, Infectious) model of epidemic spreading considers a population of \(N\) individuals each in a state \(X_{i}\in\{S,I\}\). We use the notation \(\partial i\) to define the set of individuals in contact with \(i\). At any time instant \(t\), an individual \(i\) that is susceptible can be infected by one of its infected contacts \(j\) with probability \(\lambda\). We write the joint distribution as</p> \[\begin{equation} p(x^{1},\ldots,x^{T})={\displaystyle \prod_{t}}w^{t}(x^{t}|x^{t-1})={\displaystyle \prod_{t}}\prod_{i}w_{i}^{t}(x_{i}^{t}|\{x_{j}^{t-1}\}_{j\in\partial i}) \end{equation}\] <p>with</p> \[\begin{equation} w_{i}^{t}(x_{i}^{t}=I|\{x_{j}^{t-1}\}_{j\in\partial i})=1-\prod_{j\in\partial i}\left(1-\lambda\delta(x_{j}^{t-1},I)\right). \end{equation}\] <p>The equations above describe the “free” evolution of the dynamics. What happens in the much realistic case where one introduces the observation that some individuals were tested at some point and therefore their state at that time is known? Suppose a set \(O=\{(j,s)\}_{j\in1:N,s\in1:T}\) of observations: we know that individual \(j\) was tested at time \(s\) and the result was \(y_{j}^{s}\in\{S,I\}.\)</p> <p>By Bayes’ formula (which is nothing but a corollary of the definition of conditional probability, really), the probability of an evolution \(\boldsymbol{x^{1}},\ldots,\boldsymbol{x^{T}}\) given the set of statistically independent observations \(Y=\{y_{j}^{s}\}_{j,s\in O}\) is</p> \[\begin{equation} p(\boldsymbol{x}^{1}\boldsymbol{,}\ldots\boldsymbol{,\boldsymbol{\boldsymbol{x}}}^{T}|Y)=\frac{p(Y|\boldsymbol{x}^{1}\boldsymbol{,}\ldots\boldsymbol{,\boldsymbol{\boldsymbol{x}}}^{T})p(\boldsymbol{\boldsymbol{x}^{1}\boldsymbol{,}}\ldots\boldsymbol{\boldsymbol{,\boldsymbol{\boldsymbol{x}}}}^{T})}{\sum_{\boldsymbol{\boldsymbol{x}^{1}\boldsymbol{,}\ldots\boldsymbol{,\boldsymbol{\boldsymbol{x}}}^{T}}}p(Y|\boldsymbol{x}^{1}\boldsymbol{,}\ldots\boldsymbol{,\boldsymbol{\boldsymbol{x}}}^{T})p(\boldsymbol{\boldsymbol{x}^{1}\boldsymbol{,}}\ldots\boldsymbol{\boldsymbol{,\boldsymbol{\boldsymbol{x}}}}^{T})} \end{equation}\] <p>where \(p(\boldsymbol{x}^1,\ldots,\boldsymbol{x}^T)\) is given by \((12)\) and \(p(Y|\boldsymbol{x}^{1}\boldsymbol{,}\ldots\boldsymbol{,\boldsymbol{\boldsymbol{x}}}^{T})=\prod_{(j,s)\in O}\delta(x_{j}^{s},y_{j}^{s})\). Therefore, \(p(\boldsymbol{x}^{1}\boldsymbol{,}\ldots\boldsymbol{,\boldsymbol{\boldsymbol{x}}}^{T}|Y)\) is of the form \((8)\).</p> <h2 id="now-what">Now what?</h2> <p>It is clear at this point that exact computations on reweighted Markov processes are generally not feasible. However, approximations have proposed, some of which are listed below. In most cases the goodness of an approximation depends on the particular form of \(W\) and \(\Phi\).</p> <ul> <li>The most straightforward strategy is probably a Monte Carlo approach known as importance sampling. Given some observable of interest \(\mathcal{A}(x^{1},\ldots,x^{T})\), consider its average \(A=\mathbb{E}_{p}[\mathcal{A}]={\displaystyle \frac{1}{Z}\sum_{x^{1},x^{2},\ldots,x^{T}}}\mathcal{A}(x^{1},x^{2},\ldots,x^{T})W(x^{1},x^{2},\ldots,x^{T})\Phi(x^{1},x^{2},\ldots,x^{T})\). This can be reinterpreted as \(\frac{1}{Z}\mathbb{E}_{W}[\mathcal{A}\Phi]\), the expectation of the quantity \(\mathcal{A}\Phi\) over distribution \(W\). Since \(W\) is a Markov process we know how to sample from it. To build a Monte Carlo estimate for \(A\), first draw \(M\) independent samples \(\{\underline{x}^{(\mu)},\ldots,\underline{x}^{(M)}\}\) from \(W\) (\(\underline{x}\) is short for \(x^{1},x^{2},\ldots,x^{T}\)). Then, \(\begin{equation} \hat{A}=\frac{\sum_{\mu=1}^{M}\mathcal{A}(\underline{x}^{(\mu)})\Phi(\underline{x}^{(\mu)})}{\sum_{\mu=1}^{M}\Phi(\underline{x}^{(\mu)})} \end{equation}\) To see that such approximation is a sensible choice, you can compute the expectation of the numerator and the denominator and verify that their ratio is equal to \(A\) <d-footnote>In contrast, the expected value of the ratio $\mathbb{E}\hat{A}$ is not equal to $A$! This is something I learnt while reasoning on this topic: importance sampling for unnormalized distributions gives biased estimators</d-footnote>.</li> <li>Find an “effective” Markov process which is as close as possible to the biased one. An idea is to set up a variational problem: look among a class of Markov processes for the one that minimizes the KL divergence with the target distribution \(p\propto W\Phi\) <d-cite key="causality"></d-cite>.</li> <li>And more…</li> </ul> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/reweighted_markov.bib"></d-bibliography> <div id="giscus_thread" style="max-width: 930px; margin: 0 auto;"> <script>
      let giscusTheme = determineComputedTheme();
      let giscusAttributes = {
        src: 'https://giscus.app/client.js',
        'data-repo': 'stecrotti/stecrotti.github.io',
        'data-repo-id': 'MDEwOlJlcG9zaXRvcnk2MDAyNDM2NQ==',
        'data-category': 'Comments',
        'data-category-id': 'DIC_kwDOA5PmLc4CTBt6',
        'data-mapping': 'title',
        'data-strict': '1',
        'data-reactions-enabled': '1',
        'data-emit-metadata': '0',
        'data-input-position': 'bottom',
        'data-theme': giscusTheme,
        'data-lang': 'en',
        crossorigin: 'anonymous',
        async: '',
      };

      let giscusScript = document.createElement('script');
      Object.entries(giscusAttributes).forEach(([key, value]) => giscusScript.setAttribute(key, value));
      document.getElementById('giscus_thread').appendChild(giscusScript);
    </script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Stefano Crotti. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: June 11, 2025. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>